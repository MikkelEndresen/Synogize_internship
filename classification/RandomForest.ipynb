{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd08dfa-115f-4e1d-ae4a-f106b0a2a356",
   "metadata": {
    "name": "cell4",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Random Forest Classifier for Retail_Store\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "2bad58ac-1aa5-481f-9856-9071edb6e42a",
   "metadata": {
    "name": "cell17",
    "collapsed": false,
    "resultHeight": 273
   },
   "source": "### Dependencies\n\nAdd these packages:\n- Numpy\n- Pandas\n- imbalanced-learn\n- scikit-learn\n- streamlit\n- snowflake ml"
  },
  {
   "cell_type": "code",
   "id": "f949fb8f-7567-4fa4-9338-6c7c451ed7b9",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "resultHeight": 0,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport time\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom snowflake.ml.registry import Registry\nfrom snowflake.snowpark.context import get_active_session",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f3ba7b3-efde-487c-84e3-bf8c33acd364",
   "metadata": {
    "name": "cell5",
    "collapsed": false,
    "resultHeight": 88
   },
   "source": "### Data Preparation\n\nSplitting the data in to X, and y for both train and test. Also dropping ID columns."
  },
  {
   "cell_type": "code",
   "id": "253b787f-e9e5-4501-93a7-0100e35eb204",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "codeCollapsed": false,
    "resultHeight": 60,
    "collapsed": false
   },
   "outputs": [],
   "source": "session = get_active_session()\n\nsession.use_database(\"ML\")\nsession.use_schema(\"RETAIL_STORE\")\n\ndf_model_data = session.table('model_data') # importing data\n\nstart_time = time.time()\n\n\ndf_model_data = df_model_data.drop(\"CUSTOMER_ID\", \"OFFER_PRODUCT_ID\") # dropping id columns\nX = df_model_data.drop(\"REPEATER_INT\")\ny = df_model_data.select(\"REPEATER_INT\")\n\n\nFEATURE_COLS = X.columns[:len(X.columns)]\nLABEL_COLS = [\"REPEATER_INT\"]\n\nprint(f\"Feature Columns: {FEATURE_COLS}\")\n\nX = X.to_pandas()\ny = y.to_pandas()\n\ny = y.values.ravel()\n\n# 80/20 train/test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nend_time = time.time()\nfinal_time = end_time - start_time\n\nprint(f\"\\nData Preparation time: {final_time}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e096689-db71-4a34-9a13-ab14f756d55f",
   "metadata": {
    "name": "cell12",
    "collapsed": false,
    "resultHeight": 241
   },
   "source": "### Training the Random Forest Classifier\n\n##### Using a Randomized search to find optimal paramters\n\nThere are a two main reasons why I chose to use randomized search instead of a GridSearch of manually tuning it. \n1. I don't necessarily have great reasons for choosing the various values in a param_grid without doing some manual testing first. \n2. Time and cost. Improving the model by 0.1% will have very little effect on the outcome and it would cost a lot more compute and time to do so with more thorough optimisation methods. "
  },
  {
   "cell_type": "code",
   "id": "86008e65-3786-442d-ac81-40b753d0f215",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "resultHeight": 665,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import classification_report\n\n\nstart_time = time.time()\n\nmodel = RandomForestClassifier()\n\n\nparam_dist = {\n    'n_estimators': [50, 100, 200, 500],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 5],\n    'max_features': ['sqrt', 'log2'], # dont use 'auto'. error\n}\n\n\nrandom_search = RandomizedSearchCV(\n    estimator=model,\n    param_distributions=param_dist,\n    n_iter=5, ###\n    scoring='f1',\n    cv=5,\n    verbose=2,\n    random_state=42,\n)\n\nrandom_search.fit(X_train, y_train)\n\nend_time = time.time()\ntraining_time = end_time - start_time\n\nprint(\"Training time: \", training_time) \n\nparameters = random_search.best_params_\n\nprint(\"Best Parameters:\", parameters)\nprint(\"Best Score:\", random_search.best_score_)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b72500b5-01f2-4deb-9fc6-96a12f0b9d52",
   "metadata": {
    "name": "cell9",
    "collapsed": false,
    "resultHeight": 633
   },
   "source": "##### Best Parameters\n\n**Accuracy**\n\nTraining time: 612.6654381752014\nBest Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20}  \n\n**F1 Score**\n\nTraining time: 662.3674252033234 \n\nBest Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None}  \n\n**Precision**\nTraining time:  617.7530901432037  \n\nBest Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20}  \n\nBest Score: 0.4705840774492579\n\n**Recall**\n\nIt took 666.42 seconds to train or about 11 minutes\n\n\nBest Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None}  \n\n\nBest Score: 0.30048660720508213"
  },
  {
   "cell_type": "markdown",
   "id": "84ea0976-8db5-4707-bf54-4276976961a4",
   "metadata": {
    "name": "cell15",
    "collapsed": false,
    "resultHeight": 177
   },
   "source": "### Data Preparation for different methods to deal with overfitting\n- Oversampling\n- Undersampling\n- SMOTE\n- class_weight = \"balanced.\""
  },
  {
   "cell_type": "code",
   "id": "29f292bc-2dc3-4b6b-8f85-a06ac68c8065",
   "metadata": {
    "language": "python",
    "name": "cell16",
    "codeCollapsed": false,
    "resultHeight": 150,
    "collapsed": false
   },
   "outputs": [],
   "source": "from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\n\nX_oversampled, y_oversampled = ros.fit_resample(X_train, y_train)\n\n\nprint(f\"Total num in y_train: {len(y_train)}. Number of 1's: {np.sum(y_train == 1)}. Number of 0's: {np.sum(y_train==0)}\")\nprint(f\"Total num in y_train: {len(y_oversampled)}. Number of 1's: {np.sum(y_oversampled == 1)}. Number of 0's: {np.sum(y_oversampled==0)}\")\n\n\nfrom imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler()\nX_undersampled, y_undersampled = rus.fit_resample(X_train, y_train)\n\nprint(f\"Total num in y_train: {len(y_train)}. Number of 1's: {np.sum(y_train == 1)}. Number of 0's: {np.sum(y_train==0)}\")\nprint(f\"Total num in y_train: {len(y_undersampled)}. Number of 1's: {np.sum(y_undersampled == 1)}. Number of 0's: {np.sum(y_undersampled==0)}\")\n\n\nfrom imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nX_smoted, y_smoted = smote.fit_resample(X_train, y_train)\n\nprint(f\"Total num in y_train: {len(y_train)}. Number of 1's: {np.sum(y_train == 1)}. Number of 0's: {np.sum(y_train==0)}\")\nprint(f\"Total num in y_train: {len(y_smoted)}. Number of 1's: {np.sum(y_smoted == 1)}. Number of 0's: {np.sum(y_smoted==0)}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9153643-557e-4631-853a-554acc047f4e",
   "metadata": {
    "name": "cell37",
    "collapsed": false,
    "resultHeight": 88
   },
   "source": "### Training and evaluating model\n\nUsing the optimal hyperparmeters, but also a version that is all default.\n"
  },
  {
   "cell_type": "code",
   "id": "9cc246b0-8559-4db8-841b-f69c15c85955",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "start_time = time.time()\n\n#model = RandomForestClassifier(\n    #class_weight = 'balanced'\n#)\n\n# model = RandomForestClassifier(\n#     n_estimators = 200,\n#     min_samples_split = 5,\n#     min_samples_leaf = 1,\n#     max_features = 'log2',\n#     max_depth = None, \n#     #class_weight = 'balanced'\n# )\n\n#params_precision = {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20}  \n#params_accuracy = {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20} \nparams_f1 = {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None} #'class_weight':'balanced' \n\nmodel = RandomForestClassifier(**params_f1)\n\n#model.fit(X_train, y_train)\n#model.fit(X_undersampled, y_undersampled)\n#model.fit(X_oversampled, y_oversampled)\nmodel.fit(X_smoted, y_smoted)\n\nend_time = time.time()\ntraining_time = end_time - start_time",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae5a9066-b15d-4ab5-8971-6bcdf849132d",
   "metadata": {
    "name": "cell11",
    "collapsed": false,
    "resultHeight": 47
   },
   "source": "#### Feature Importance and Estimators"
  },
  {
   "cell_type": "code",
   "id": "fb788c25-dd07-4dc8-800a-5f964af2cc75",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false,
    "resultHeight": 105,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "importances = model.feature_importances_\nparameters = model.get_params()\nestimators = model.estimators_\n\nprint(\"Feature importance:\", importances) #sklearn_model.get_params())\nprint(\"Estimators:\", estimators[0])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "223e5a44-aa10-4adf-ac46-a3d44f8ca7e5",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "collapsed": false,
    "resultHeight": 195,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# predict\nstart_time = time.time()\n\npredictions = model.predict(X_test)\n\nend_time = time.time()\nprediction_time = end_time - start_time\nprint(f\"Prediction time: {prediction_time}\")\nprint(f\"Predictions: {predictions}\")\n\nprint(classification_report(y_test, predictions))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "783fc167-fa43-447d-9905-22acb15546ff",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "collapsed": false,
    "resultHeight": 172,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, confusion_matrix\n\naccuracy = accuracy_score(y_test, predictions)\nprint(f'Accuracy: {accuracy:.4f}')\n\nrecall = recall_score(y_test, predictions)\nprint(f'Recall: {recall:.4f}')\n\nprecision = precision_score(y_test, predictions)\nprint(f'Precision: {precision:.4f}')\n\nf1_score = f1_score(y_test, predictions)\nprint(f'F1 Score: {f1_score:.4f}')\n\n\nconf_matrix = confusion_matrix(y_test, predictions)\nprint('Confusion Matrix:')\nprint(conf_matrix)\n\n# For storing in db\ntrue_positive = conf_matrix[1][1]  \ntrue_negative = conf_matrix[0][0]  \nfalse_positive = conf_matrix[0][1]  \nfalse_negative = conf_matrix[1][0]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb295e08-4d0a-472b-b533-0ecb540a741e",
   "metadata": {
    "name": "cell25",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "**Record Performance functinon**"
  },
  {
   "cell_type": "code",
   "id": "0251a95b-aca9-4ebe-8329-46b6ee6274a7",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "codeCollapsed": false,
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "import json\n\ndef record_performance(true_positive, true_negative, false_positive, false_negative, model_name, accuracy, recall, training_time, prediction_time, \n         parameters, coefficients, intercept, notes):\n\n    confusion_matrix_insert_sql = f\"\"\"\n        insert into model_results_schema.confusion_matrix\n        (true_positive, true_negative, false_positive, false_negative)\n        values\n        ({true_positive}, {true_negative}, {false_positive}, {false_negative});\n    \"\"\"\n    \n    session.sql(confusion_matrix_insert_sql).collect()\n\n    last_id_sql = \"\"\"\n        select id\n        from model_results_schema.confusion_matrix\n        order by create_at desc\n        limit 1;\n    \"\"\" \n\n    #SELECT LAST_VALUE(id) OVER (ORDER BY id RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_id\n    confusion_matrix_id = session.sql(last_id_sql).collect()\n    confusion_matrix_id = confusion_matrix_id[0]['ID']\n\n    # These two need to be on a string format.\n    if coefficients != \"\":\n        coefficients = ', '.join(map(str, coefficients))\n    parameters = json.dumps(parameters)\n    \n    # Insert data into the model_performance table\n    session.sql(f\"\"\"\n        insert into model_results_schema.model_performance\n            (model_name, accuracy, recall, confusion_matrix_id,\n            training_time, prediction_time, parameters, coefficients,\n            intercept, notes)\n        values\n            ('{model_name}', {accuracy}, {recall}, {confusion_matrix_id}, {training_time}, {prediction_time}, '{parameters}', '{coefficients}', {intercept}, '{notes}');\n    \"\"\").collect()\n\n    \n    return \"success\"\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bbd7f016-7977-4f37-874c-cb08fcb8c376",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "codeCollapsed": false,
    "collapsed": false,
    "resultHeight": 38
   },
   "outputs": [],
   "source": "\nnotes = \"precision:\" + str(precision) + \"| f1_score: \" + str(f1_score) # precision score\nmodel_name = \"RF-f1_score-smote\"\n\n# record_performance(true_positive, true_negative, false_positive, false_negative, model_name, accuracy, recall, training_time, prediction_time, \n         #parameters, coefficients, intercept, notes):\nresult = record_performance(true_positive, true_negative, false_positive, false_negative, model_name, accuracy, recall, training_time, prediction_time, \n         parameters, [0], 0.0, notes)\nprint(result)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0a8f2f57-ea27-442a-8400-1ee0899002c8",
   "metadata": {
    "name": "cell18",
    "collapsed": false,
    "resultHeight": 60
   },
   "source": "## Review Results"
  },
  {
   "cell_type": "code",
   "id": "cb0e90a0-5eac-4ed6-a892-178f969e2ef0",
   "metadata": {
    "language": "sql",
    "name": "cell19",
    "codeCollapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "use database ml;\nuse schema model_results_schema;\n\nselect * from model_performance\norder by accuracy desc;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb58c0af-c7c7-4651-a1f9-d2ce18886717",
   "metadata": {
    "language": "sql",
    "name": "cell38",
    "resultHeight": 438,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "select * from confusion_matrix;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aa7cd904-93ad-40c0-8960-e1c47af2eb56",
   "metadata": {
    "language": "python",
    "name": "cell41",
    "resultHeight": 38,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "print(8343 / len(y_test)*100)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d48e372c-e78e-4fc9-a0d6-e4612d786d43",
   "metadata": {
    "name": "cell20",
    "collapsed": false,
    "resultHeight": 60
   },
   "source": "## Probability thresholds\n"
  },
  {
   "cell_type": "code",
   "id": "a4b06f9f-db95-41ca-b5f2-3ea2c2c14ea5",
   "metadata": {
    "language": "sql",
    "name": "cell42",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "use schema retail_store;\nselect count(distinct customer_id) from transactions;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3b2d0ed-3074-47e1-bdc7-be06a35a26ce",
   "metadata": {
    "language": "python",
    "name": "cell40",
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# using the best model\n\nmodel = RandomForestClassifier(\n    n_estimators = 200,\n    min_samples_split = 5,\n    min_samples_leaf = 1,\n    max_features = 'log2',\n    max_depth = None\n)\n\nmodel.fit(X_undersampled, y_undersampled)\n\npredictions = model.predict(X_test)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2effa592-05ef-4a3b-9dca-2a141a8554a1",
   "metadata": {
    "language": "python",
    "name": "cell39",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "453b4278-8682-46e8-a9cf-7452ee811d4f",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "codeCollapsed": false,
    "resultHeight": 559065
   },
   "outputs": [],
   "source": "from sklearn.metrics import precision_recall_curve\n\nprobabilities = model.predict_proba(X_test)[:, 1]\nprecision, recall, thresholds = precision_recall_curve(y_test, probabilities)\n\nfor i in range(0, len(recall)-1):\n    print(f\"Recall: {recall[i]}, threshold: {thresholds[i]}\")\n\nplt.plot(thresholds, precision[:-1], label='Precision')\nplt.plot(thresholds, recall[:-1], label='Recall')\nplt.xlabel('Threshold')\nplt.ylabel('Score')\nplt.title('Precision and Recall vs. Threshold')\nplt.legend()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94dac9b3-a5a7-4382-a136-a99ca57451b3",
   "metadata": {
    "language": "python",
    "name": "cell22",
    "codeCollapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# chosen threshold. 95% recall\n#threshold = 0.028952380952380955 \n\n#y_pred = (probabilities >= threshold).astype(int)\n\n# threshold for where precision meets recall (ish)\n\nthreshold = 0.75\ny_pred = (probabilities >= threshold).astype(int)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bddcd9cc-46fe-46ee-9a38-dc8a6a29f20f",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "codeCollapsed": false,
    "resultHeight": 127
   },
   "outputs": [],
   "source": "accuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy:.4f}')\n\nrecall = recall_score(y_test, y_pred)\nprint(f'Recall: {recall:.4f}')\n\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix:')\nprint(conf_matrix)\n\n# For storing in db\ntrue_positive = conf_matrix[1][1]  \ntrue_negative = conf_matrix[0][0]  \nfalse_positive = conf_matrix[0][1]  \nfalse_negative = conf_matrix[1][0]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1eb463b8-84dd-4e12-a8c4-c72dcf48b973",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "codeCollapsed": false,
    "resultHeight": 38
   },
   "outputs": [],
   "source": "\nnotes = \"\"\nmodel_name = \"RF-optimal-params-undersampled-threshold=0.75\"\n\nresult = record_performance(true_positive, true_negative, false_positive, false_negative, model_name, accuracy, recall, training_time, prediction_time, \n         parameters, [0], 0.0, notes)\nprint(result)",
   "execution_count": null
  }
 ]
}